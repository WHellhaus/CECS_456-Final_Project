{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Classifier for Chess Openings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "\n",
    "def LoadData(num_to_exclude, truncate_ply, move_tokenizer):\n",
    "    to_exclude = [i for i in range(1, num_to_exclude)]# specifies the amount of data to load in (leave list empty to load all data)\n",
    "    games = pd.read_csv('games.csv', header=0, encoding='latin-1', skiprows=to_exclude)\n",
    "    opening_cats = {'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4}\n",
    "    labels = []\n",
    "    for index, row in games.iterrows():\n",
    "        labels.append(opening_cats[row['opening_eco'][0]])\n",
    "    games = pd.concat([games, pd.DataFrame({'label': labels})], axis=1)\n",
    "    headers = list(games.columns.values)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(games.to_numpy(), labels, test_size=0.33)\n",
    "    X_train = pd.DataFrame(data=X_train, columns=headers)\n",
    "    X_test = pd.DataFrame(data=X_test, columns=headers)\n",
    "\n",
    "    # dictionary for how to tokenize moves into a list\n",
    "    # by ply: split by  each move of white or black\n",
    "    # by turn: split by each turn i.e. one white move and one black move\n",
    "    # by turn with number: split by turn and add the number of the turn to the beginning of the string (psuedo-dependency)\n",
    "    move_tokenizer_options = {'by ply': 0, 'by turn': 1, 'by turn with number': 2}\n",
    "\n",
    "    games, mcw = processGames(X_train, truncate_ply[0], move_tokenizer_options[move_tokenizer], opening_cats)\n",
    "    test, mcw_test = processGames(X_test, truncate_ply[1], move_tokenizer_options[move_tokenizer], opening_cats)\n",
    "    return games, test, mcw\n",
    "\n",
    "def processGames(games, truncate_ply, move_tokenizer, opening_cats):\n",
    "    data = [games['moves'], games['opening_eco']]\n",
    "    ply = games['opening_ply']\n",
    "    headers = ['moves', 'opening']\n",
    "    data = pd.concat(data, axis=1, keys=headers)\n",
    "    maxPly = 14\n",
    "\n",
    "    for index, row in data.iterrows():\n",
    "        row['opening'] = opening_cats[row['opening'][0]]\n",
    "        ply[index] = ply[index]+1 if (ply[index] % 2 != 0) else ply[index]\n",
    "        moveCount = 0\n",
    "        moves = word_tokenize(row['moves'])\n",
    "\n",
    "        if (move_tokenizer == 0):\n",
    "            if(truncate_ply):\n",
    "                row['moves'] = moves[0:ply[index]+1]\n",
    "            else:\n",
    "                row['moves'] = moves[0:maxPly+1]\n",
    "        else:\n",
    "            formattedMoves = []\n",
    "            for move in moves:\n",
    "                if(truncate_ply): \n",
    "                    if (moveCount >= (ply[index])):\n",
    "                        break\n",
    "                elif (moveCount >= maxPly):\n",
    "                    break\n",
    "\n",
    "                if(move_tokenizer == 1):\n",
    "                    if(moveCount%2==0):\n",
    "                        formattedMoves.append(str(move))\n",
    "                    else:\n",
    "                        formattedMoves[int(moveCount/2)] += ' ' + str(move)\n",
    "                if(move_tokenizer == 2):\n",
    "                    if(moveCount%2==0):\n",
    "                        formattedMoves.append(str(int(moveCount/2)+1) + '.' + str(move))\n",
    "                    else:\n",
    "                        formattedMoves[int(moveCount/2)] += ' ' + str(move)\t\n",
    "\n",
    "                moveCount += 1\n",
    "            row['moves'] = formattedMoves\n",
    "\n",
    "    mcw = []\n",
    "    for key in opening_cats:\n",
    "        rows = data.loc[data['opening'] == opening_cats[key]]\n",
    "        # print(key, rows)\n",
    "        moves = []\n",
    "        for index, row in rows.iterrows():\n",
    "            moves += row['moves']\n",
    "        mcw.append(MostCommonWords(moves))\n",
    "    return data, mcw\n",
    "\n",
    "\n",
    "# This function calculates the requency of words using NLTK\n",
    "# Input: data in string format\n",
    "# Output: data_dist is a data dictionary like NLTK object\n",
    "def MostCommonWords(data):\n",
    "    data_dist = FreqDist(data)\n",
    "    return data_dist\n",
    "\n",
    "def Prob_Word_GivenY(word, train_data, numWords, alpha, y):\n",
    "    sum = 0\n",
    "    count_y = 0\n",
    "    for i, row in train_data.iterrows():\n",
    "        if(row['feature_list'].get(word)):\n",
    "            if(row['opening']==y and row['feature_list'].get(word)>0):\n",
    "                sum += 1\n",
    "                count_y += 1\n",
    "    return (sum + alpha) / (count_y + numWords*alpha)\n",
    "\n",
    "def Classify2(moves, p_category, train_splits, numWords, alpha, categories):\n",
    "    p_cat_given_moves = [x for x in p_category]\n",
    "\n",
    "    for move in moves:\n",
    "        for key, value in categories.items():\n",
    "            p_cat_given_moves[value] *= Prob_Word_GivenY(move, train_splits[value], numWords, alpha, value)\n",
    "    return p_cat_given_moves.index(max(p_cat_given_moves))\n",
    "\n",
    "def Training2(train_data, train_wc, categories, test_data):\n",
    "    dictionary = set()\n",
    "    for frqdist in train_wc:\n",
    "        dictionary = dictionary.union(set(frqdist.keys()))\n",
    "\n",
    "    m = [len(x[1]) for x in train_data.groupby('opening')]\n",
    "\n",
    "    alpha = 1\n",
    "\n",
    "    p = [(m_cat + 1) / (sum(m) + len(categories)*alpha) for m_cat in m]\n",
    "\n",
    "    num_words = [len(frqdist) for frqdist in train_wc]\n",
    "\n",
    "    train_data['feature_list'] = \"\"\n",
    "    for i, row in train_data.iterrows():\n",
    "        word_map = {}\n",
    "        for word in dictionary:\n",
    "            word_map[word] = row['moves'].count(word)\n",
    "        row['feature_list'] = word_map\n",
    "\n",
    "    train_splits = [x[1] for x in train_data.groupby('opening')]\n",
    "\n",
    "    correct = 0\n",
    "    shape = np.zeros(shape=(len(categories), len(categories)))\n",
    "    conf_matrix = pd.DataFrame(shape)\n",
    "    for i, row in test_data.iterrows():\n",
    "        prediction = Classify2(row['moves'], p, train_splits, sum(num_words), alpha, categories)\n",
    "        conf_matrix.iat[prediction, row['opening']] += 1\n",
    "        correct += 1 if prediction == row['opening'] else 0\n",
    "        # print(prediction, row['opening'])\n",
    "    print('ACCURACY: ', correct/len(test_data))\n",
    "    print(conf_matrix)\n",
    "\n",
    "\n",
    "# def main():\n",
    "#     opening_cats = {'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4}\n",
    "#     games, test,  mcw = LoadData()\n",
    "#     Training2(games, mcw, opening_cats, test)\n",
    "\n",
    "# main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACY:  0.8648648648648649\n",
      "      0     1     2     3     4\n",
      "0  28.0   0.0   0.0   1.0   2.0\n",
      "1   2.0  44.0   0.0   1.0   1.0\n",
      "2   6.0   6.0  62.0   4.0   0.0\n",
      "3   0.0   0.0   0.0  14.0   0.0\n",
      "4   1.0   1.0   0.0   0.0  12.0\n"
     ]
    }
   ],
   "source": [
    "opening_cats = {'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4}\n",
    "games, test, mcw = LoadData(19500, [True, False], 'by turn with number')\n",
    "Training2(games, mcw, opening_cats, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
