{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Data Processing Functions\n",
    "To properly import and process the data from our csv file we will need functions to import the data, extract the relevant information, convert the information into the desired labels, and numericize the text into data the model can interpret."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Definitions and imports have finished loading.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#returns a pandas dataframe with the data from a specified csv file\n",
    "def loadData(filename):\n",
    "    data = pd.read_csv(filename)\n",
    "    return data\n",
    "\n",
    "#returns one of 13 chess opening subtypes given a specific opening\n",
    "def openType(openStr):\n",
    "    open = openStr[0]\n",
    "    num = int(openStr[1:])\n",
    "    if (openStr[0] == 'A'):\n",
    "        if (num < 40):\n",
    "            open += '00'\n",
    "        elif (num < 45):\n",
    "            open += '40'\n",
    "        elif (num < 50):\n",
    "            open += '45'\n",
    "        elif (num < 80):\n",
    "            open += '50'\n",
    "        else:\n",
    "            open += '80'\n",
    "    if (openStr[0] == 'B'):\n",
    "        if (num < 20):\n",
    "            open += '00'\n",
    "        else:\n",
    "            open += '20'\n",
    "    if (openStr[0] == 'C'):\n",
    "        if (num < 20):\n",
    "            open += '00'\n",
    "        else:\n",
    "            open += '20'\n",
    "    if (openStr[0] == 'D'):\n",
    "        if (num < 70):\n",
    "            open += '00'\n",
    "        else:\n",
    "            open += '70'\n",
    "    if (openStr[0] == 'E'):\n",
    "        if (num < 60):\n",
    "            open += '00'\n",
    "        else:\n",
    "            open += '60'\n",
    "    return open\n",
    "\n",
    "#returns a dataset and labelset from a pandas dataframe\n",
    "#the returned dataset includes the first (openingPly) moves preformed\n",
    "#the returned labelset is the opening subtype defined by the moves preformed in the dataset\n",
    "def dataExtraction(baseData):\n",
    "    data = []\n",
    "    labels = []\n",
    "    \n",
    "    for i in range(len(baseData.index)):\n",
    "        row = baseData.iloc[i, :]\n",
    "        opening = []\n",
    "        moveText = row[12].split()\n",
    "        for j in range(row[15]):\n",
    "            opening.append(moveText[j])\n",
    "        data.append(opening)\n",
    "        labels.append(openType(row[13]))\n",
    "    \n",
    "    return data, labels\n",
    "\n",
    "#returns a numericized version of the input array along with the dictionary used for conversion\n",
    "def numericize(textData):\n",
    "    numericDic = {}\n",
    "    conversion = []\n",
    "    if type(textData[0]) != list:\n",
    "        for label in textData:\n",
    "            if label not in numericDic:\n",
    "                numericDic[label] = len(numericDic)\n",
    "            conversion.append(numericDic[label])\n",
    "    else:\n",
    "        for text in textData:\n",
    "            moveList = []\n",
    "            for move in text:\n",
    "                if move not in numericDic:\n",
    "                    numericDic[move] = len(numericDic) + 1 #avoids the 0 index to avoid value overlap with padding\n",
    "                moveList.append(numericDic[move])\n",
    "            conversion.append(moveList)\n",
    "            \n",
    "    return numericDic, conversion\n",
    "\n",
    "#outputs a notification to the user that jupyter has finished loading the code block\n",
    "print(\"Definitions and imports have finished loading.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Preprocessing the Data\n",
    "Using the functions defined above, data will be preprocessed into its desired format. Aside from the methods already mentioned, data is padded to match the length of the longest opening ply and divided into training and testing subsets at an 80-20 split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been loaded and preprocessed.\n"
     ]
    }
   ],
   "source": [
    "#imports preprocessing libraries\n",
    "from keras.preprocessing import sequence\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#implements the methods defined in the previous block to numericize the games.csv data\n",
    "data = loadData(\"games.csv\")\n",
    "maxMoves = max(data.iloc[:,15])   #stores the maximum opening ply value for padding\n",
    "moves, labels = dataExtraction(data)\n",
    "moveDic, numMoves = numericize(moves)\n",
    "labelDic, numLabels = numericize(labels)\n",
    "numLabels = np.array(numLabels)   #reformats the label data into a numpy array for consistent data structures\n",
    "\n",
    "#pads the input data with 0's to ensure all input data is the same size\n",
    "numMoves = sequence.pad_sequences(numMoves, maxlen=maxMoves)\n",
    "\n",
    "#builds subsets for testing and training data at an 80-20 split\n",
    "X_train, X_test, y_train, y_test = train_test_split(numMoves, numLabels, test_size=0.2, stratify=numLabels)\n",
    "\n",
    "#outputs a notification to the user that jupyter has finished loading the code block\n",
    "print(\"Data has been loaded and preprocessed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Creating and compiling the RNN model\n",
    "Here we build the recurrent neural network model using our imported tools, compile the model, and train it on our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "201/201 [==============================] - 11s 42ms/step - loss: 1.4137 - accuracy: 0.5725 - val_loss: 0.2046 - val_accuracy: 0.9439\n",
      "Epoch 2/5\n",
      "201/201 [==============================] - 8s 39ms/step - loss: 0.1613 - accuracy: 0.9586 - val_loss: 0.0830 - val_accuracy: 0.9766\n",
      "Epoch 3/5\n",
      "201/201 [==============================] - 8s 39ms/step - loss: 0.0682 - accuracy: 0.9825 - val_loss: 0.0451 - val_accuracy: 0.9903\n",
      "Epoch 4/5\n",
      "201/201 [==============================] - 8s 39ms/step - loss: 0.0385 - accuracy: 0.9918 - val_loss: 0.0379 - val_accuracy: 0.9900\n",
      "Epoch 5/5\n",
      "201/201 [==============================] - 8s 39ms/step - loss: 0.0237 - accuracy: 0.9951 - val_loss: 0.0279 - val_accuracy: 0.9950\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x14f7971b850>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#imports the necessary libraries for model creation\n",
    "from keras import Sequential\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "\n",
    "#converts our numeric label data into a binary classification matrix\n",
    "y_train_bin = to_categorical(y_train)\n",
    "y_test_bin = to_categorical(y_test)\n",
    "\n",
    "#builds our model layer by layer\n",
    "embedding_size=300     #it is challenging to lock down a perfect value, research says 100-300 is standard\n",
    "model = Sequential()   #initializes the model\n",
    "#converts moves to dense vectors based on surrounding moves\n",
    "model.add(Embedding(len(moveDic)+1, embedding_size, input_length=maxMoves))\n",
    "model.add(LSTM(100))   #adds long short-term memory layer with an output shape of 100\n",
    "model.add(Dense(13, activation='softmax'))   #condenses estimation to 13 labels and uses 'softmax' to select the highest value\n",
    "\n",
    "#compiles the model using categorical crossentropy for multi-label classification\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "#trains the model over the specified number of epochs\n",
    "batch_size = 64 #potentially trivial\n",
    "num_epochs = 5\n",
    "model.fit(X_train, y_train_bin, batch_size=batch_size, epochs=num_epochs, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Scoring the model\n",
    "Note - multiple trials may require require rerunning the program from step 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.9947656989097595\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(X_test, y_test_bin, verbose=0)\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
